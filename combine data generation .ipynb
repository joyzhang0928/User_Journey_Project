{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4ebd3b-3101-4505-b5ca-df8be9cf1a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-27.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /opt/anaconda3/lib/python3.11/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-27.4.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-27.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec3d7a-fa79-4a7d-9f03-7e0d5af34ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Score Bias: Adjust the Interest_Rate and Application_Status based on the Credit_Score. Higher credit scores will have lower interest rates and a higher likelihood of approval.\n",
    "# Geographic Bias: Influence the Promotions field based on the Location. Certain locations will have a higher chance of receiving better promotional offers.\n",
    "# increase Sample Size: Update n_samples to 70,000.\n",
    "# Introduce Missing Data: Use probabilities to assign None values to certain fields at random, representing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fdd877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize Faker to generate synthetic data\n",
    "fake = Faker()\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 2000\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)  # For random.sample and random.choice in non-numpy contexts\n",
    "\n",
    "def generate_correlated_features(num_samples):\n",
    "    \"\"\"\n",
    "    Generate correlated personal and financial features.\n",
    "    \"\"\"\n",
    "    # Generate Age with normal distribution, clipped between 18 and 80\n",
    "    age = np.random.normal(40, 12, num_samples).clip(18, 80).astype(int)\n",
    "    \n",
    "    # Generate Experience based on Age, ensuring non-negative\n",
    "    experience = (age - 18 - np.random.normal(4, 2, num_samples)).clip(0).astype(int)\n",
    "    \n",
    "    # Generate Education Level with predefined probabilities\n",
    "    education_level = np.random.choice(\n",
    "        ['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate'], \n",
    "        num_samples, \n",
    "        p=[0.3, 0.2, 0.3, 0.15, 0.05]\n",
    "    )\n",
    "    \n",
    "    # Impact of Education on Income and Credit Score\n",
    "    edu_impact = {'High School': 0, 'Associate': 0.1, 'Bachelor': 0.2, 'Master': 0.3, 'Doctorate': 0.4}\n",
    "    edu_factor = np.array([edu_impact[level] for level in education_level])\n",
    "    \n",
    "    # Generate Annual Income using log-normal distribution influenced by education and experience\n",
    "    base_income = np.random.lognormal(10.5, 0.6, num_samples) * (1 + edu_factor) * (1 + experience / 100)\n",
    "    income_noise = np.random.normal(0, 0.1, num_samples)\n",
    "    annual_income = (base_income * (1 + income_noise)).clip(15000, 300000).astype(int)\n",
    "    \n",
    "    # Generate Credit Score influenced by education, experience, and income\n",
    "    credit_score_base = 300 + 300 * stats.beta.rvs(5, 1.5, size=num_samples)\n",
    "    credit_score = (credit_score_base + edu_factor * 100 + experience * 1.5 + income_noise * 100).clip(300, 850).astype(int)\n",
    "    \n",
    "    # Generate Employment Status probabilities based on education\n",
    "    employment_status_probs = np.column_stack([\n",
    "        0.9 - edu_factor * 0.3,  # Employed\n",
    "        0.05 + edu_factor * 0.2,  # Self-Employed\n",
    "        0.05 + edu_factor * 0.1   # Unemployed\n",
    "    ])\n",
    "    # Normalize probabilities to sum to 1\n",
    "    employment_status_probs = employment_status_probs / employment_status_probs.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Assign Employment Status based on probabilities\n",
    "    employment_status = np.array(['Employed', 'Self-Employed', 'Unemployed'])[\n",
    "        np.argmax(np.random.random((num_samples, 1)) < employment_status_probs.cumsum(axis=1), axis=1)\n",
    "    ]\n",
    "    \n",
    "    return age, experience, education_level, annual_income, credit_score, employment_status\n",
    "\n",
    "def generate_time_based_features(num_samples):\n",
    "    \"\"\"\n",
    "    Generate sequential application dates starting from January 1, 2018.\n",
    "    \"\"\"\n",
    "    start_date = datetime(2018, 1, 1)\n",
    "    dates = [start_date + timedelta(days=i) for i in range(num_samples)]\n",
    "    return dates\n",
    "\n",
    "# Generate correlated features\n",
    "age, experience, education_level, annual_income, credit_score, employment_status = generate_correlated_features(num_samples)\n",
    "application_dates = generate_time_based_features(num_samples)\n",
    "\n",
    "# Define a dictionary mapping vehicle makes to possible models\n",
    "make_model_mapping = {\n",
    "    'Toyota': ['Camry', 'Corolla', 'RAV4', 'Prius', 'Highlander', 'Tacoma'],\n",
    "    'Honda': ['Civic', 'Accord', 'CR-V', 'Pilot', 'Fit', 'Odyssey'],\n",
    "    'Ford': ['F-150', 'Escape', 'Explorer', 'Mustang', 'Fusion', 'Ranger'],\n",
    "    'Chevrolet': ['Silverado', 'Equinox', 'Malibu', 'Traverse', 'Camaro', 'Tahoe'],\n",
    "    'BMW': ['3 Series', '5 Series', 'X3', 'X5', '7 Series', 'X1'],\n",
    "    'Mercedes-Benz': ['C-Class', 'E-Class', 'GLC', 'GLE', 'S-Class', 'GLA'],\n",
    "    'Nissan': ['Altima', 'Sentra', 'Rogue', 'Versa', 'Pathfinder', 'Maxima'],\n",
    "    'Hyundai': ['Elantra', 'Sonata', 'Tucson', 'Santa Fe', 'Accent', 'Kona'],\n",
    "    'Kia': ['Soul', 'Optima', 'Sportage', 'Sorento', 'Rio', 'Seltos'],\n",
    "    'Subaru': ['Forester', 'Outback', 'Impreza', 'Crosstrek', 'Legacy', 'Ascent'],\n",
    "    'Mazda': ['CX-5', 'Mazda3', 'Mazda6', 'MX-5 Miata', 'CX-9', 'Mazda CX-30'],\n",
    "    'Audi': ['A3', 'A4', 'A6', 'Q5', 'Q7', 'TT'],\n",
    "    'Volkswagen': ['Golf', 'Passat', 'Tiguan', 'Jetta', 'Atlas', 'Arteon'],\n",
    "    'Volvo': ['XC90', 'S60', 'S90', 'XC60', 'V60', 'V90'],\n",
    "    'Porsche': ['911', 'Cayenne', 'Macan', 'Panamera', 'Taycan', 'Boxster'],\n",
    "    'Jeep': ['Wrangler', 'Grand Cherokee', 'Renegade', 'Compass', 'Cherokee', 'Gladiator'],\n",
    "    'Lexus': ['RX', 'ES', 'NX', 'GX', 'LS', 'IS'],\n",
    "    'Acura': ['MDX', 'RDX', 'TLX', 'ILX', 'RLX', 'NSX'],\n",
    "    'Cadillac': ['Escalade', 'XT5', 'CT5', 'XT4', 'ATS', 'XT6'],\n",
    "    'Lincoln': ['Navigator', 'Aviator', 'Corsair', 'Nautilus', 'MKZ', 'MKC'],\n",
    "    'Infiniti': ['Q50', 'QX60', 'QX80', 'Q30', 'QX50', 'QX55'],\n",
    "    'Genesis': ['G70', 'G80', 'G90', 'GV70', 'GV80', 'G70 Convertible'],\n",
    "    'Bentley': ['Continental', 'Flying Spur', 'Bentayga', 'Mulsanne', 'Azure'],\n",
    "    'Maserati': ['Ghibli', 'Quattroporte', 'Levante', 'GranTurismo', 'MC20'],\n",
    "    'Alfa Romeo': ['Giulia', 'Stelvio', '4C', 'Giulietta', 'Tonale', 'GT'],\n",
    "    'Fiat': ['500', 'Panda', '124 Spider', 'Tipo', '500X', '500L'],\n",
    "    'Mitsubishi': ['Outlander', 'Eclipse Cross', 'Mirage', 'Galant', 'Lancer', 'ASX'],\n",
    "    'Mini': ['Cooper', 'Countryman', 'Clubman', 'Convertible', 'Hardtop'],\n",
    "    'Ram': ['1500', '2500', '3500', 'ProMaster', 'Chassis Cab'],\n",
    "    'Suzuki': ['Swift', 'Vitara', 'Jimny', 'Baleno', 'Celerio', 'S-Cross']\n",
    "}\n",
    "\n",
    "# Expanded list of vehicle makes with approximate weights (illustrative)\n",
    "vehicle_makes = list(make_model_mapping.keys())\n",
    "\n",
    "# Corresponding weights (adjust based on actual market data as needed)\n",
    "vehicle_make_weights = [\n",
    "    10,  # Toyota\n",
    "    9,   # Honda\n",
    "    8,   # Ford\n",
    "    7,   # Chevrolet\n",
    "    6,   # BMW\n",
    "    5,   # Mercedes-Benz\n",
    "    6,   # Nissan\n",
    "    5,   # Hyundai\n",
    "    5,   # Kia\n",
    "    4,   # Subaru\n",
    "    3,   # Mazda\n",
    "    3,   # Audi\n",
    "    2,   # Volkswagen\n",
    "    2,   # Volvo\n",
    "    1,   # Porsche\n",
    "    4,   # Jeep\n",
    "    3,   # Lexus\n",
    "    2,   # Acura\n",
    "    1,   # Cadillac\n",
    "    1,   # Lincoln\n",
    "    2,   # Infiniti\n",
    "    2,   # Genesis\n",
    "    1,   # Bentley\n",
    "    1,   # Maserati\n",
    "    1,   # Alfa Romeo\n",
    "    1,   # Fiat\n",
    "    1,   # Mitsubishi\n",
    "    1,   # Mini\n",
    "    1,   # Ram\n",
    "    1    # Suzuki\n",
    "]\n",
    "\n",
    "# Convert weights to probabilities\n",
    "total_weight = sum(vehicle_make_weights)\n",
    "vehicle_make_probabilities = [weight / total_weight for weight in vehicle_make_weights]\n",
    "\n",
    "# Generate Vehicle_Make data based on probabilities\n",
    "vehicle_make_data = np.random.choice(\n",
    "    vehicle_makes, \n",
    "    size=num_samples, \n",
    "    p=vehicle_make_probabilities\n",
    ")\n",
    "\n",
    "# Function to assign a model based on make\n",
    "def assign_model(make):\n",
    "    return random.choice(make_model_mapping.get(make, ['Model_Not_Specified']))\n",
    "\n",
    "# Generate Vehicle_Model data based on Vehicle_Make\n",
    "vehicle_model_data = [assign_model(make) for make in vehicle_make_data]\n",
    "\n",
    "# Define probabilities for Vehicle_Type\n",
    "vehicle_type_probs = [0.4, 0.6]  # 40% New, 60% Used\n",
    "\n",
    "# Generate Vehicle_Type data\n",
    "vehicle_type_data = np.random.choice(['New', 'Used'], size=num_samples, p=vehicle_type_probs)\n",
    "\n",
    "# Generate Vehicle_Year based on Vehicle_Type\n",
    "vehicle_year_data = []\n",
    "for vt in vehicle_type_data:\n",
    "    if vt == 'New':\n",
    "        # New vehicles: Recent years (e.g., 2018-2024)\n",
    "        year = np.random.randint(2018, 2025)\n",
    "    else:\n",
    "        # Used vehicles: Older years (e.g., 2005-2017)\n",
    "        year = np.random.randint(2005, 2018)\n",
    "    vehicle_year_data.append(year)\n",
    "\n",
    "# Generate Vehicle_Mileage based on Vehicle_Year and Vehicle_Type\n",
    "vehicle_mileage_data = []\n",
    "current_year = 2024\n",
    "\n",
    "for year, vt in zip(vehicle_year_data, vehicle_type_data):\n",
    "    age = current_year - year\n",
    "    if vt == 'New':\n",
    "        # New vehicles: Low mileage, e.g., 0-30,000 miles\n",
    "        mileage = np.random.randint(0, 30001)\n",
    "    else:\n",
    "        # Used vehicles: Mileage increases with age, e.g., 30,000 + (age * 12,000) +/- 10,000\n",
    "        avg_mileage = age * 12000\n",
    "        min_mileage = max(avg_mileage - 10000, 30000)\n",
    "        max_mileage = avg_mileage + 10000\n",
    "        mileage = np.random.randint(min_mileage, max_mileage + 1)\n",
    "    vehicle_mileage_data.append(mileage)\n",
    "\n",
    "# Define base prices for each Vehicle_Make (in USD)\n",
    "base_price_mapping = {\n",
    "    'Toyota': 25000,\n",
    "    'Honda': 24000,\n",
    "    'Ford': 26000,\n",
    "    'Chevrolet': 25500,\n",
    "    'BMW': 45000,\n",
    "    'Mercedes-Benz': 47000,\n",
    "    'Nissan': 23000,\n",
    "    'Hyundai': 22000,\n",
    "    'Kia': 21000,\n",
    "    'Subaru': 23500,\n",
    "    'Mazda': 22500,\n",
    "    'Audi': 44000,\n",
    "    'Volkswagen': 20000,\n",
    "    'Volvo': 42000,\n",
    "    'Porsche': 60000,\n",
    "    'Jeep': 28000,\n",
    "    'Lexus': 43000,\n",
    "    'Acura': 39000,\n",
    "    'Cadillac': 50000,\n",
    "    'Lincoln': 48000,\n",
    "    'Infiniti': 40000,\n",
    "    'Genesis': 41000,\n",
    "    'Bentley': 90000,\n",
    "    'Maserati': 85000,\n",
    "    'Alfa Romeo': 37000,\n",
    "    'Fiat': 18000,\n",
    "    'Mitsubishi': 19000,\n",
    "    'Mini': 22000,\n",
    "    'Ram': 30000,\n",
    "    'Suzuki': 17000\n",
    "}\n",
    "\n",
    "# Assign base price to each vehicle based on Vehicle_Make\n",
    "vehicle_price_data = []\n",
    "for make in vehicle_make_data:\n",
    "    base_price = base_price_mapping.get(make, 20000)  # Default base price if make not found\n",
    "    vehicle_price_data.append(base_price)\n",
    "\n",
    "# Adjust Vehicle_Price based on Vehicle_Type, Vehicle_Year, and Vehicle_Mileage\n",
    "adjusted_vehicle_price_data = []\n",
    "for i in range(num_samples):\n",
    "    make = vehicle_make_data[i]\n",
    "    base_price = base_price_mapping.get(make, 20000)\n",
    "    vt = vehicle_type_data[i]\n",
    "    year = vehicle_year_data[i]\n",
    "    mileage = vehicle_mileage_data[i]\n",
    "    \n",
    "    if vt == 'New':\n",
    "        # New vehicles: Slight adjustment for models or additional features can be added here\n",
    "        price = base_price\n",
    "    else:\n",
    "        # Used vehicles: Apply depreciation based on age and mileage\n",
    "        age = current_year - year\n",
    "        # Depreciation rate: 5% per year\n",
    "        depreciation = 0.05 * age\n",
    "        # Mileage factor: Assume higher mileage reduces price\n",
    "        mileage_factor = min(mileage / 150000, 1)  # Cap at 1\n",
    "        mileage_depreciation = 0.2 * mileage_factor  # Up to 20% depreciation based on mileage\n",
    "        \n",
    "        total_depreciation = depreciation + mileage_depreciation\n",
    "        total_depreciation = min(total_depreciation, 0.8)  # Cap total depreciation at 80%\n",
    "        \n",
    "        price = base_price * (1 - total_depreciation)\n",
    "    \n",
    "    # Add some randomness (±5%)\n",
    "    price *= np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Ensure price is not negative\n",
    "    price = max(price, 1000)\n",
    "    \n",
    "    adjusted_vehicle_price_data.append(int(price))\n",
    "\n",
    "# Define Loan_Amount based on Vehicle_Price and Vehicle_Type\n",
    "loan_amount_data = []\n",
    "for i in range(num_samples):\n",
    "    price = adjusted_vehicle_price_data[i]\n",
    "    vt = vehicle_type_data[i]\n",
    "    \n",
    "    if vt == 'New':\n",
    "        # New vehicles: LTV between 80% - 100%\n",
    "        ltv = np.random.uniform(0.8, 1.0)\n",
    "    else:\n",
    "        # Used vehicles: LTV between 50% - 80%\n",
    "        ltv = np.random.uniform(0.5, 0.8)\n",
    "    \n",
    "    loan_amount = price * ltv\n",
    "    \n",
    "    # Add some randomness (±5%)\n",
    "    loan_amount *= np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Ensure loan amount does not exceed vehicle price\n",
    "    loan_amount = min(loan_amount, price)\n",
    "    \n",
    "    # Convert to integer\n",
    "    loan_amount_data.append(int(loan_amount))\n",
    "\n",
    "# Generate Location data using Faker\n",
    "location_data = [fake.city() for _ in range(num_samples)]\n",
    "\n",
    "# Generate Down_Payment as a percentage of Vehicle_Price (10% - 30%)\n",
    "down_payment_data = []\n",
    "for price in adjusted_vehicle_price_data:\n",
    "    down_payment = np.random.randint(int(price * 0.1), int(price * 0.3) + 1)\n",
    "    down_payment_data.append(down_payment)\n",
    "\n",
    "# Generate Loan_Tenure_Years based on Loan_Amount\n",
    "loan_tenure_data = []\n",
    "for loan in loan_amount_data:\n",
    "    if loan > 30000:\n",
    "        tenure = np.random.choice([5, 6, 7], p=[0.5, 0.3, 0.2])\n",
    "    elif loan > 20000:\n",
    "        tenure = np.random.choice([4, 5, 6], p=[0.4, 0.4, 0.2])\n",
    "    else:\n",
    "        tenure = np.random.choice([3, 4, 5], p=[0.5, 0.3, 0.2])\n",
    "    loan_tenure_data.append(tenure)\n",
    "\n",
    "# Generate Interest_Rate based on Credit_Score, Loan_Amount, Loan_Tenure_Years, and Annual_Income\n",
    "interest_rate_data = []\n",
    "for credit, loan, tenure, income in zip(credit_score, loan_amount_data, loan_tenure_data, annual_income):\n",
    "    base_rate = 2.0  # Base interest rate\n",
    "    # Higher credit score reduces interest rate\n",
    "    credit_factor = (850 - credit) / 2000  # Scaled factor\n",
    "    # Higher loan amount may increase interest rate\n",
    "    loan_factor = (loan - 5000) / 100000  # Scaled factor\n",
    "    # Longer tenure may increase interest rate\n",
    "    tenure_factor = (tenure - 3) * 0.2\n",
    "    # Higher income may reduce interest rate\n",
    "    income_factor = (income - 50000) / 200000  # Scaled factor\n",
    "    \n",
    "    interest = base_rate + credit_factor + loan_factor + tenure_factor - income_factor\n",
    "    # Add some randomness\n",
    "    interest += np.random.uniform(-0.3, 0.3)\n",
    "    # Clip interest rate to realistic bounds\n",
    "    interest = min(max(interest, 1.9), 6.5)\n",
    "    interest_rate_data.append(round(interest, 2))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# Initialize the data dictionary with existing fields (excluding 'Debt_To_Income_Ratio')\n",
    "data = {\n",
    "    'User_ID': [fake.uuid4() for _ in range(num_samples)],\n",
    "    'ApplicationDate': application_dates,\n",
    "    'Age': age,\n",
    "    'Gender': np.random.choice(['Male', 'Female'], size=num_samples),\n",
    "    'Annual_Income': annual_income,\n",
    "    'Credit_Score': credit_score,\n",
    "    'Employment_Status': employment_status,\n",
    "    'Education_Level': education_level,\n",
    "    'Experience': experience,\n",
    "    'Loan_Amount': loan_amount_data,  # Dependency-based Loan_Amount\n",
    "    'Loan_Duration': np.random.choice(\n",
    "        [12, 24, 36, 48, 60, 72, 84, 96, 108, 120], \n",
    "        num_samples, \n",
    "        p=[0.05, 0.1, 0.2, 0.2, 0.2, 0.1, 0.05, 0.05, 0.025, 0.025]\n",
    "    ),\n",
    "    'Marital_Status': np.random.choice(\n",
    "        ['Single', 'Married', 'Divorced', 'Widowed'], \n",
    "        num_samples, \n",
    "        p=[0.3, 0.5, 0.15, 0.05]\n",
    "    ),\n",
    "    'Number_Of_Dependents': np.random.choice(\n",
    "        [0, 1, 2, 3, 4, 5], \n",
    "        num_samples, \n",
    "        p=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03]\n",
    "    ),\n",
    "    'Home_Ownership_Status': np.random.choice(\n",
    "        ['Own', 'Rent', 'Mortgage', 'Other'], \n",
    "        num_samples, \n",
    "        p=[0.2, 0.3, 0.4, 0.1]\n",
    "    ),\n",
    "    'Monthly_Debt_Payments': np.random.lognormal(6, 0.5, num_samples).astype(int),\n",
    "    'Credit_Card_Utilization_Rate': np.random.beta(2, 5, num_samples),\n",
    "    'Number_Of_Open_CreditLines': np.random.poisson(3, num_samples).clip(0, 15).astype(int),\n",
    "    'Number_Of_Credit_Inquiries': np.random.poisson(1, num_samples).clip(0, 10).astype(int),\n",
    "    'Debt_To_IncomeRatio': np.random.beta(2, 5, num_samples),  # Removed 'Debt_To_Income_Ratio'\n",
    "    'Bankruptcy_History': np.random.choice([0, 1], num_samples, p=[0.95, 0.05]),\n",
    "    'Previous_Loan_Defaults': np.random.choice([0, 1], num_samples, p=[0.9, 0.1]),\n",
    "    'Payment_History': np.random.poisson(24, num_samples).clip(0, 60).astype(int),\n",
    "    'Length_Of_CreditHistory': np.random.randint(1, 30, num_samples),\n",
    "    'Savings_Account_Balance': np.random.lognormal(8, 1, num_samples).astype(int),\n",
    "    'Checking_Account_Balance': np.random.lognormal(7, 1, num_samples).astype(int),\n",
    "    'Total_Assets': np.random.lognormal(11, 1, num_samples).astype(int),\n",
    "    'Total_Liabilities': np.random.lognormal(10, 1, num_samples).astype(int),\n",
    "    'Monthly_Income': annual_income / 12,\n",
    "    'Utility_Bills_Payment_History': np.random.beta(8, 2, num_samples),\n",
    "    'Job_Tenure': np.random.poisson(5, num_samples).clip(0, 40).astype(int),\n",
    "    \n",
    "    'Location': location_data,\n",
    "    'Vehicle_Type': vehicle_type_data,\n",
    "    'Vehicle_Make': vehicle_make_data,\n",
    "    'Vehicle_Model': vehicle_model_data,\n",
    "    'Vehicle_Year': vehicle_year_data,\n",
    "    'Vehicle_Mileage': vehicle_mileage_data,\n",
    "    'Vehicle_Price': adjusted_vehicle_price_data,\n",
    "    'Down_Payment': down_payment_data,\n",
    "    'Loan_Tenure_Years': loan_tenure_data,\n",
    "    'Interest_Rate': interest_rate_data,\n",
    "    # 'Application_Status' will be determined via the loan approval function\n",
    "    'Session_Duration_Minutes': np.random.randint(5, 60, size=num_samples),\n",
    "    'Number_of_Interactions': np.random.randint(10, 100, size=num_samples),\n",
    "    'Notifications_Responded': np.random.choice([0, 1], size=num_samples, p=[0.7, 0.3]),\n",
    "    'Support_Queries': np.random.choice([0, 1, 2, 3], size=num_samples, p=[0.5, 0.3, 0.15, 0.05]),\n",
    "    'Application_Submitted': np.random.choice([True, False], size=num_samples, p=[0.8, 0.2])\n",
    "}\n",
    "\n",
    "# Define additional fields to be added\n",
    "marital_statuses = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "device_types = ['iPhone', 'Android', 'Windows Phone']\n",
    "os_versions = ['iOS 15', 'iOS 14', 'Android 11', 'Android 10', 'Windows 10 Mobile']\n",
    "app_versions = ['1.0', '1.1', '1.2']\n",
    "network_types = ['Wi-Fi', '4G', '5G']\n",
    "dealer_info = ['Dealer A', 'Dealer B', 'Dealer C', 'Dealer D']\n",
    "promotions = ['0% APR', '$1000 Cashback', 'No Payments for 90 Days', 'Low Down Payment']\n",
    "event_sequences = ['Application Start', 'Vehicle Selection', 'Loan Calculator', 'Document Upload', 'Credit Check', 'Approval']\n",
    "screens = ['Home', 'Loan Calculator', 'Vehicle Selection', 'Document Upload', 'Credit Check', 'Approval']\n",
    "\n",
    "data.update({\n",
    "    \"Monthly_Expenses\": np.random.randint(1000, 10000, size=num_samples),\n",
    "    \"Previous_Vehicle_Ownership\": np.random.choice([True, False], size=num_samples, p=[0.7, 0.3]),\n",
    "    \"Trade_In_Details\": np.random.choice([None, 'Old Car Trade-In'], size=num_samples, p=[0.7, 0.3]),\n",
    "    \"Session_Start_Time\": [fake.date_time_this_year() for _ in range(num_samples)],\n",
    "    \"Session_End_Time\": [fake.date_time_this_year() for _ in range(num_samples)],\n",
    "    \"Navigation_Paths\": [random.sample(event_sequences, k=random.randint(3, len(event_sequences))) for _ in range(num_samples)],\n",
    "    \n",
    "    \"Device_Type\": np.random.choice(device_types, size=num_samples),\n",
    "    \"OS_Version\": np.random.choice(os_versions, size=num_samples),\n",
    "    \"App_Version\": np.random.choice(app_versions, size=num_samples),\n",
    "    \"Network_Type\": np.random.choice(network_types, size=num_samples),\n",
    "    \"Dealer_Info\": np.random.choice(dealer_info, size=num_samples),\n",
    "    \"Promotions\": np.random.choice(promotions, size=num_samples),\n",
    " \n",
    "    \n",
    "    \"Regulatory_Compliance\": np.random.choice(['Compliant', 'Non-Compliant'], size=num_samples, p=[0.95, 0.05]),\n",
    "    \"Consent_Provided\": np.random.choice([True, False], size=num_samples, p=[0.98, 0.02]),\n",
    "    \"User_Type\": np.random.choice(['New', 'Returning'], size=num_samples),\n",
    "    \"Behavioral_Segment\": np.random.choice(['Low Engagement', 'Medium Engagement', 'High Engagement'], size=num_samples),\n",
    "    \"User_Feedback_Rating\": np.random.randint(1, 5, size=num_samples),\n",
    "    \"Common_Issues_Faced\": np.random.choice(\n",
    "        [None, 'Document Upload Failed', 'Credit Check Issue', 'App Crash'], \n",
    "        size=num_samples, \n",
    "        p=[0.7, 0.1, 0.1, 0.1]\n",
    "    ),\n",
    "    \"User_Satisfaction\": np.random.choice(\n",
    "        ['Very Satisfied', 'Satisfied', 'Neutral', 'Dissatisfied', 'Very Dissatisfied'], \n",
    "        size=num_samples\n",
    "    )\n",
    "})\n",
    "\n",
    "# Additional Interaction Event data to be added\n",
    "data.update({\n",
    "    \"Frequency_of_App_Usage\": np.random.randint(1, 30, size=num_samples),  # Frequency of app usage in the past month\n",
    "    \"Clicks\": np.random.randint(1, 50, size=num_samples),\n",
    "    \"Taps\": np.random.randint(1, 50, size=num_samples),\n",
    "    \"Swipes\": np.random.randint(1, 50, size=num_samples),\n",
    "    \"Form_Entries\": np.random.randint(1, 20, size=num_samples),\n",
    "    \"Time_Spent_on_Home_Screen_Minutes\": np.random.randint(1, 10, size=num_samples),\n",
    "    \"Time_Spent_on_Loan_Calculator_Minutes\": np.random.randint(1, 15, size=num_samples),\n",
    "    \"Time_Spent_on_Vehicle_Selection_Minutes\": np.random.randint(1, 20, size=num_samples),\n",
    "    \"Time_Spent_on_Document_Upload_Minutes\": np.random.randint(1, 10, size=num_samples),\n",
    "    \"Time_Spent_on_Credit_Check_Minutes\": np.random.randint(1, 5, size=num_samples),\n",
    "    \"Time_Spent_on_Approval_Screen_Minutes\": np.random.randint(1, 5, size=num_samples),\n",
    "    \"Common_Paths\": [random.sample(screens, k=random.randint(3, len(screens))) for _ in range(num_samples)],\n",
    "    \"Drop_Off_Point\": np.random.choice(\n",
    "        screens + [None], \n",
    "        size=num_samples, \n",
    "        p=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.4]  # 40% complete all steps\n",
    "    ),\n",
    "    \"Comparison_of_Loan_Options\": np.random.choice([True, False], size=num_samples, p=[0.6, 0.4])\n",
    "})\n",
    "\n",
    "# Create the DataFrame with all existing and new fields\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Debt_To_IncomeRatio based on Monthly_Debt_Payments, MonthlyLoanPayment, and Monthly_Income\n",
    "df['Debt_To_IncomeRatio'] = (\n",
    "    df['Monthly_Debt_Payments'] + df['Loan_Amount'] * (df['Interest_Rate']/100)/12 / (1 - (1 + df['Interest_Rate']/100/12)**(-df['Loan_Tenure_Years']*12))\n",
    ") / df['Monthly_Income']\n",
    "\n",
    "# Create NetWorth ensuring a minimum value\n",
    "min_net_worth = 1000  # Set a minimum net worth\n",
    "df['NetWorth'] = np.maximum(df['Total_Assets'] - df['Total_Liabilities'], min_net_worth)\n",
    "\n",
    "# Calculate MonthlyLoanPayment using the loan amortization formula\n",
    "# Formula: P = (L * c) / (1 - (1 + c)^-n)\n",
    "# Where:\n",
    "# P = monthly payment\n",
    "# L = loan amount\n",
    "# c = monthly interest rate\n",
    "# n = number of payments\n",
    "\n",
    "df['MonthlyLoanPayment'] = (\n",
    "    (df['Loan_Amount'] * (df['Interest_Rate']/100) / 12) / \n",
    "    (1 - (1 + df['Interest_Rate']/100 / 12) ** (-df['Loan_Tenure_Years'] * 12))\n",
    ").fillna(0).round(2)\n",
    "\n",
    "# Recalculate Debt_To_IncomeRatio with MonthlyLoanPayment\n",
    "df['Debt_To_IncomeRatio'] = (\n",
    "    df['Monthly_Debt_Payments'] + df['MonthlyLoanPayment']\n",
    ") / df['Monthly_Income']\n",
    "\n",
    "# Define a function to calculate approval probability based on multiple factors, with increased weight for DTI and Credit Score\n",
    "def calculate_approval_probability(employment_status, credit_score, dti, loan_amount, vehicle_type, annual_income):\n",
    "    \"\"\"\n",
    "    Calculate the probability of loan approval based on employment status, credit score, DTI, loan amount, vehicle type, and annual income.\n",
    "    Increased weight is given to Credit Score and Debt-To-Income Ratio.\n",
    "    \"\"\"\n",
    "    probability = 0.0\n",
    "    \n",
    "    # Employment Status Factor\n",
    "    if employment_status == 'Employed':\n",
    "        probability += 0.2\n",
    "    elif employment_status == 'Self-Employed':\n",
    "        probability += 0.15\n",
    "    elif employment_status == 'Unemployed':\n",
    "        probability -= 0.25  # Negative impact\n",
    "    \n",
    "    # Credit Score Factor (Increased Weight)\n",
    "    if credit_score >= 750:\n",
    "        probability += 0.35\n",
    "    elif 700 <= credit_score < 750:\n",
    "        probability += 0.25\n",
    "    elif 650 <= credit_score < 700:\n",
    "        probability += 0.15\n",
    "    else:\n",
    "        probability -= 0.35  # Negative impact for low scores\n",
    "    \n",
    "    # Debt-To-Income Ratio Factor (Increased Weight)\n",
    "    if dti <= 0.25:\n",
    "        probability += 0.35\n",
    "    elif 0.25 < dti <= 0.35:\n",
    "        probability += 0.25\n",
    "    elif 0.35 < dti <= 0.45:\n",
    "        probability += 0.15\n",
    "    else:\n",
    "        probability -= 0.35  # Negative impact for high DTI\n",
    "    \n",
    "    # Loan Amount Factor\n",
    "    if loan_amount <= 20000:\n",
    "        probability += 0.15\n",
    "    elif 20000 < loan_amount <= 40000:\n",
    "        probability += 0.1\n",
    "    else:\n",
    "        probability -= 0.25  # Negative impact for very high loans\n",
    "    \n",
    "    # Annual Income Factor\n",
    "    if annual_income >= 100000:\n",
    "        probability += 0.25\n",
    "    elif 75000 <= annual_income < 100000:\n",
    "        probability += 0.2\n",
    "    elif 50000 <= annual_income < 75000:\n",
    "        probability += 0.1\n",
    "    else:\n",
    "        probability -= 0.25  # Negative impact for low income\n",
    "    \n",
    "    # Vehicle Type Factor\n",
    "    if vehicle_type == 'New':\n",
    "        probability += 0.1  # Slightly higher chance for new vehicles\n",
    "    else:\n",
    "        probability += 0.0  # No additional impact for used vehicles\n",
    "    \n",
    "    # Normalize probability to be between 0 and 1\n",
    "    probability = max(min(probability, 1.0), 0.0)\n",
    "    \n",
    "    # Determine Application Status based on probability thresholds\n",
    "    if probability >= 0.75:\n",
    "        status = 'Approved'\n",
    "    elif probability >= 0.45:\n",
    "        status = 'Pending'\n",
    "    else:\n",
    "        status = 'Rejected'\n",
    "    \n",
    "    return status\n",
    "\n",
    "# Apply the loan approval rule to each row using DataFrame.apply\n",
    "df['LoanApproved'] = df.apply(\n",
    "    lambda row: calculate_approval_probability(\n",
    "        row['Employment_Status'], \n",
    "        row['Credit_Score'], \n",
    "        row['Debt_To_IncomeRatio'], \n",
    "        row['Loan_Amount'], \n",
    "        row['Vehicle_Type'], \n",
    "        row['Annual_Income']\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ensure that if \"LoanApproved\" is \"Approved\", then \"Drop_Off_Point\" should only show \"Approval\"\n",
    "df.loc[df['LoanApproved'] == 'Approved', 'Drop_Off_Point'] = 'Approval'\n",
    "\n",
    "# Define possible treatments with a higher probability for \"Ads\" when Drop_Off_Point is \"Approval\"\n",
    "treatments = ['Ads', 'No-Ads']\n",
    "\n",
    "# Create a new column 'Treatment_Assignment' initialized with None\n",
    "df['Treatment_Assignment'] = None\n",
    "\n",
    "# Filter rows where 'Drop_Off_Point' is 'Approval'\n",
    "approval_condition = df['Drop_Off_Point'] == 'Approval'\n",
    "non_approval_condition = df['Drop_Off_Point'].isin(['Document Upload', 'Credit Check'])\n",
    "\n",
    "# Assign treatments with higher probability for \"Ads\" when 'Drop_Off_Point' is 'Approval'\n",
    "df.loc[approval_condition, 'Treatment_Assignment'] = np.random.choice(\n",
    "    treatments, size=approval_condition.sum(), p=[0.8, 0.2]\n",
    ")\n",
    "\n",
    "# Assign random treatment to the non-approval filtered rows\n",
    "df.loc[non_approval_condition, 'Treatment_Assignment'] = np.random.choice(\n",
    "    treatments, size=non_approval_condition.sum(), p=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Assign 'No-Ads' to all other rows where 'Treatment_Assignment' is still None\n",
    "df['Treatment_Assignment'].fillna('No-Ads', inplace=True)\n",
    "\n",
    "# Ensure Total_Assets is always greater than or equal to the sum of Savings_Account_Balance and Checking_Account_Balance\n",
    "df['Total_Assets'] = np.maximum(df['Total_Assets'], df['Savings_Account_Balance'] + df['Checking_Account_Balance'])\n",
    "\n",
    "# Add more complex derived features\n",
    "df['NetWorth'] = np.maximum(df['Total_Assets'] - df['Total_Liabilities'], min_net_worth)\n",
    "\n",
    "# Add some noise and outliers\n",
    "noise_mask = np.random.choice([True, False], num_samples, p=[0.01, 0.99])\n",
    "df.loc[noise_mask, 'Annual_Income'] = (\n",
    "    df.loc[noise_mask, 'Annual_Income'] * np.random.uniform(1.5, 2.0, noise_mask.sum())\n",
    ").astype(int)\n",
    "\n",
    "low_net_worth_mask = df['NetWorth'] == min_net_worth\n",
    "df.loc[low_net_worth_mask, 'NetWorth'] += np.random.randint(0, 10000, size=low_net_worth_mask.sum())\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "csv_file_path = \"Synthetic_Auto_Loan_Application_Data_jz3.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad8d660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================\n",
    "# Initialization and Constants\n",
    "# ==========================\n",
    "\n",
    "# Initialize Faker for synthetic data generation\n",
    "fake = Faker()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "NUM_SAMPLES = 20000\n",
    "\n",
    "# Current year for calculations\n",
    "CURRENT_YEAR = 2024\n",
    "\n",
    "# Vehicle make to models mapping\n",
    "MAKE_MODEL_MAPPING = {\n",
    "    'Toyota': ['Camry', 'Corolla', 'RAV4', 'Prius', 'Highlander', 'Tacoma'],\n",
    "    'Honda': ['Civic', 'Accord', 'CR-V', 'Pilot', 'Fit', 'Odyssey'],\n",
    "    'Ford': ['F-150', 'Escape', 'Explorer', 'Mustang', 'Fusion', 'Ranger'],\n",
    "    'Chevrolet': ['Silverado', 'Equinox', 'Malibu', 'Traverse', 'Camaro', 'Tahoe'],\n",
    "    'BMW': ['3 Series', '5 Series', 'X3', 'X5', '7 Series', 'X1'],\n",
    "    'Mercedes-Benz': ['C-Class', 'E-Class', 'GLC', 'GLE', 'S-Class', 'GLA'],\n",
    "    'Nissan': ['Altima', 'Sentra', 'Rogue', 'Versa', 'Pathfinder', 'Maxima'],\n",
    "    'Hyundai': ['Elantra', 'Sonata', 'Tucson', 'Santa Fe', 'Accent', 'Kona'],\n",
    "    'Kia': ['Soul', 'Optima', 'Sportage', 'Sorento', 'Rio', 'Seltos'],\n",
    "    'Subaru': ['Forester', 'Outback', 'Impreza', 'Crosstrek', 'Legacy', 'Ascent'],\n",
    "    'Mazda': ['CX-5', 'Mazda3', 'Mazda6', 'MX-5 Miata', 'CX-9', 'Mazda CX-30'],\n",
    "    'Audi': ['A3', 'A4', 'A6', 'Q5', 'Q7', 'TT'],\n",
    "    'Volkswagen': ['Golf', 'Passat', 'Tiguan', 'Jetta', 'Atlas', 'Arteon'],\n",
    "    'Volvo': ['XC90', 'S60', 'S90', 'XC60', 'V60', 'V90'],\n",
    "    'Porsche': ['911', 'Cayenne', 'Macan', 'Panamera', 'Taycan', 'Boxster'],\n",
    "    'Jeep': ['Wrangler', 'Grand Cherokee', 'Renegade', 'Compass', 'Cherokee', 'Gladiator'],\n",
    "    'Lexus': ['RX', 'ES', 'NX', 'GX', 'LS', 'IS'],\n",
    "    'Acura': ['MDX', 'RDX', 'TLX', 'ILX', 'RLX', 'NSX'],\n",
    "    'Cadillac': ['Escalade', 'XT5', 'CT5', 'XT4', 'ATS', 'XT6'],\n",
    "    'Lincoln': ['Navigator', 'Aviator', 'Corsair', 'Nautilus', 'MKZ', 'MKC'],\n",
    "    'Infiniti': ['Q50', 'QX60', 'QX80', 'Q30', 'QX50', 'QX55'],\n",
    "    'Genesis': ['G70', 'G80', 'G90', 'GV70', 'GV80', 'G70 Convertible'],\n",
    "    'Bentley': ['Continental', 'Flying Spur', 'Bentayga', 'Mulsanne', 'Azure'],\n",
    "    'Maserati': ['Ghibli', 'Quattroporte', 'Levante', 'GranTurismo', 'MC20'],\n",
    "    'Alfa Romeo': ['Giulia', 'Stelvio', '4C', 'Giulietta', 'Tonale', 'GT'],\n",
    "    'Fiat': ['500', 'Panda', '124 Spider', 'Tipo', '500X', '500L'],\n",
    "    'Mitsubishi': ['Outlander', 'Eclipse Cross', 'Mirage', 'Galant', 'Lancer', 'ASX'],\n",
    "    'Mini': ['Cooper', 'Countryman', 'Clubman', 'Convertible', 'Hardtop'],\n",
    "    'Ram': ['1500', '2500', '3500', 'ProMaster', 'Chassis Cab'],\n",
    "    'Suzuki': ['Swift', 'Vitara', 'Jimny', 'Baleno', 'Celerio', 'S-Cross']\n",
    "}\n",
    "\n",
    "# Vehicle make weights for probability distribution\n",
    "VEHICLE_MAKE_WEIGHTS = [\n",
    "    10, 9, 8, 7, 6, 5, 6, 5, 5, 4, 3, 3, 2, 2, 1,\n",
    "    4, 3, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1\n",
    "]\n",
    "\n",
    "VEHICLE_MAKES = list(MAKE_MODEL_MAPPING.keys())\n",
    "\n",
    "# Ensure VEHICLE_MAKE_WEIGHTS matches the length of VEHICLE_MAKES\n",
    "assert len(VEHICLE_MAKE_WEIGHTS) == len(VEHICLE_MAKES), \"Weights and makes length mismatch.\"\n",
    "\n",
    "# Base price mapping for vehicle makes\n",
    "BASE_PRICE_MAPPING = {\n",
    "    'Toyota': 25000,\n",
    "    'Honda': 24000,\n",
    "    'Ford': 26000,\n",
    "    'Chevrolet': 25500,\n",
    "    'BMW': 45000,\n",
    "    'Mercedes-Benz': 47000,\n",
    "    'Nissan': 23000,\n",
    "    'Hyundai': 22000,\n",
    "    'Kia': 21000,\n",
    "    'Subaru': 23500,\n",
    "    'Mazda': 22500,\n",
    "    'Audi': 44000,\n",
    "    'Volkswagen': 20000,\n",
    "    'Volvo': 42000,\n",
    "    'Porsche': 60000,\n",
    "    'Jeep': 28000,\n",
    "    'Lexus': 43000,\n",
    "    'Acura': 39000,\n",
    "    'Cadillac': 50000,\n",
    "    'Lincoln': 48000,\n",
    "    'Infiniti': 40000,\n",
    "    'Genesis': 41000,\n",
    "    'Bentley': 90000,\n",
    "    'Maserati': 85000,\n",
    "    'Alfa Romeo': 37000,\n",
    "    'Fiat': 18000,\n",
    "    'Mitsubishi': 19000,\n",
    "    'Mini': 22000,\n",
    "    'Ram': 30000,\n",
    "    'Suzuki': 17000\n",
    "}\n",
    "\n",
    "# Treatment options\n",
    "TREATMENTS = ['Ads', 'No-Ads']\n",
    "\n",
    "# Event sequences and screens for user interactions\n",
    "EVENT_SEQUENCES = ['Application Start', 'Vehicle Selection', 'Loan Calculator', 'Document Upload', 'Credit Check', 'Approval']\n",
    "SCREENS = ['Home', 'Loan Calculator', 'Vehicle Selection', 'Document Upload', 'Credit Check', 'Approval']\n",
    "\n",
    "# ==========================\n",
    "# Helper Functions\n",
    "# ==========================\n",
    "\n",
    "def generate_correlated_features(num_samples):\n",
    "    \"\"\"\n",
    "    Generate correlated personal and financial features.\n",
    "    \"\"\"\n",
    "    # Age: Normal distribution, clipped between 18 and 80\n",
    "    age = np.random.normal(40, 12, num_samples).clip(18, 80).astype(int)\n",
    "    \n",
    "    # Experience: Based on Age, ensuring non-negative\n",
    "    experience = (age - 18 - np.random.normal(4, 2, num_samples)).clip(0).astype(int)\n",
    "    \n",
    "    # Education Level with predefined probabilities\n",
    "    education_levels = ['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate']\n",
    "    education_probs = [0.3, 0.2, 0.3, 0.15, 0.05]\n",
    "    education_level = np.random.choice(education_levels, num_samples, p=education_probs)\n",
    "    \n",
    "    # Education Impact on Income and Credit Score\n",
    "    edu_impact = {'High School': 0, 'Associate': 0.1, 'Bachelor': 0.2, 'Master': 0.3, 'Doctorate': 0.4}\n",
    "    edu_factor = np.array([edu_impact[level] for level in education_level])\n",
    "    \n",
    "    # Annual Income: Log-normal distribution influenced by education and experience\n",
    "    base_income = np.random.lognormal(10.5, 0.6, num_samples) * (1 + edu_factor) * (1 + experience / 100)\n",
    "    income_noise = np.random.normal(0, 0.1, num_samples)\n",
    "    annual_income = (base_income * (1 + income_noise)).clip(15000, 300000).astype(int)\n",
    "    \n",
    "    # Credit Score: Influenced by education, experience, and income\n",
    "    credit_score_base = 300 + 300 * stats.beta.rvs(5, 1.5, size=num_samples)\n",
    "    credit_score = (credit_score_base + edu_factor * 100 + experience * 1.5 + income_noise * 100).clip(300, 850).astype(int)\n",
    "    \n",
    "    # Employment Status based on education\n",
    "    employment_status_probs = np.column_stack([\n",
    "        0.9 - edu_factor * 0.3,  # Employed\n",
    "        0.05 + edu_factor * 0.2,  # Self-Employed\n",
    "        0.05 + edu_factor * 0.1   # Unemployed\n",
    "    ])\n",
    "    employment_status_probs /= employment_status_probs.sum(axis=1, keepdims=True)  # Normalize\n",
    "    \n",
    "    employment_status = np.array(['Employed', 'Self-Employed', 'Unemployed'])[\n",
    "        np.argmax(np.random.random((num_samples, 1)) < employment_status_probs.cumsum(axis=1), axis=1)\n",
    "    ]\n",
    "    \n",
    "    return age, experience, education_level, annual_income, credit_score, employment_status\n",
    "\n",
    "def generate_application_dates(num_samples):\n",
    "    \"\"\"\n",
    "    Generate sequential application dates starting from January 1, 2018.\n",
    "    \"\"\"\n",
    "    start_date = datetime(2018, 1, 1)\n",
    "    return [start_date + timedelta(days=i) for i in range(num_samples)]\n",
    "\n",
    "def assign_vehicle_model(make):\n",
    "    \"\"\"\n",
    "    Assign a vehicle model based on the make.\n",
    "    \"\"\"\n",
    "    return random.choice(MAKE_MODEL_MAPPING.get(make, ['Model_Not_Specified']))\n",
    "\n",
    "def generate_vehicle_features(num_samples, vehicle_makes):\n",
    "    \"\"\"\n",
    "    Generate vehicle-related features.\n",
    "    \"\"\"\n",
    "    # Vehicle Model\n",
    "    vehicle_models = [assign_vehicle_model(make) for make in vehicle_makes]\n",
    "    \n",
    "    # Vehicle Type\n",
    "    vehicle_type_probs = [0.4, 0.6]  # New vs Used\n",
    "    vehicle_types = np.random.choice(['New', 'Used'], size=num_samples, p=vehicle_type_probs)\n",
    "    \n",
    "    # Vehicle Year\n",
    "    vehicle_years = np.where(\n",
    "        vehicle_types == 'New',\n",
    "        np.random.randint(2018, CURRENT_YEAR + 1, num_samples),\n",
    "        np.random.randint(2005, 2018, num_samples)\n",
    "    )\n",
    "    \n",
    "    # Vehicle Mileage\n",
    "    age = CURRENT_YEAR - vehicle_years\n",
    "    mileage_new = np.random.randint(0, 30001, num_samples)\n",
    "    mileage_used = 30000 + (age * 12000) + np.random.randint(-10000, 10001, num_samples)\n",
    "    mileage_used = mileage_used.clip(30000, None)\n",
    "    vehicle_mileage = np.where(vehicle_types == 'New', mileage_new, mileage_used).astype(int)\n",
    "    \n",
    "    return vehicle_types, vehicle_models, vehicle_years, vehicle_mileage\n",
    "\n",
    "def generate_vehicle_price(num_samples, vehicle_makes, vehicle_types, vehicle_years, vehicle_mileage):\n",
    "    \"\"\"\n",
    "    Generate vehicle prices based on type, year, and mileage.\n",
    "    \"\"\"\n",
    "    base_prices = np.array([BASE_PRICE_MAPPING.get(make, 20000) for make in vehicle_makes])\n",
    "    \n",
    "    # Depreciation for used vehicles\n",
    "    age = CURRENT_YEAR - vehicle_years\n",
    "    depreciation = 0.05 * age\n",
    "    mileage_factor = np.minimum(vehicle_mileage / 150000, 1)\n",
    "    mileage_depreciation = 0.2 * mileage_factor\n",
    "    total_depreciation = depreciation + mileage_depreciation\n",
    "    total_depreciation = np.minimum(total_depreciation, 0.8)  # Cap at 80%\n",
    "    \n",
    "    # Calculate price\n",
    "    prices = np.where(\n",
    "        vehicle_types == 'New',\n",
    "        base_prices,\n",
    "        base_prices * (1 - total_depreciation)\n",
    "    )\n",
    "    \n",
    "    # Add randomness ±5%\n",
    "    prices *= np.random.uniform(0.95, 1.05, num_samples)\n",
    "    prices = np.maximum(prices, 1000).astype(int)\n",
    "    \n",
    "    return prices\n",
    "\n",
    "def generate_loan_amount(prices, vehicle_types):\n",
    "    \"\"\"\n",
    "    Generate loan amounts based on vehicle price and type.\n",
    "    \"\"\"\n",
    "    ltv_new = np.random.uniform(0.8, 1.0, NUM_SAMPLES)\n",
    "    ltv_used = np.random.uniform(0.5, 0.8, NUM_SAMPLES)\n",
    "    ltv = np.where(vehicle_types == 'New', ltv_new, ltv_used)\n",
    "    \n",
    "    loan_amount = prices * ltv\n",
    "    loan_amount *= np.random.uniform(0.95, 1.05, NUM_SAMPLES)  # Add randomness ±5%\n",
    "    loan_amount = np.minimum(loan_amount, prices).astype(int)\n",
    "    \n",
    "    return loan_amount\n",
    "\n",
    "def generate_interest_rate(credit_scores, loan_amounts, loan_tenures, annual_incomes):\n",
    "    \"\"\"\n",
    "    Generate interest rates based on multiple financial factors.\n",
    "    \"\"\"\n",
    "    base_rate = 2.0\n",
    "    credit_factor = (850 - credit_scores) / 2000\n",
    "    loan_factor = (loan_amounts - 5000) / 100000\n",
    "    tenure_factor = (loan_tenures - 3) * 0.2\n",
    "    income_factor = (annual_incomes - 50000) / 200000\n",
    "    \n",
    "    interest = base_rate + credit_factor + loan_factor + tenure_factor - income_factor\n",
    "    interest += np.random.uniform(-0.3, 0.3, NUM_SAMPLES)  # Add randomness\n",
    "    interest = np.clip(interest, 1.9, 6.5).round(2)\n",
    "    \n",
    "    return interest\n",
    "\n",
    "def calculate_monthly_loan_payment(loan_amount, interest_rate, tenure_years):\n",
    "    \"\"\"\n",
    "    Calculate monthly loan payment using the amortization formula.\n",
    "    \"\"\"\n",
    "    monthly_rate = interest_rate / 100 / 12\n",
    "    num_payments = tenure_years * 12\n",
    "    payment = (loan_amount * monthly_rate) / (1 - (1 + monthly_rate) ** -num_payments)\n",
    "    payment = np.where(\n",
    "        monthly_rate > 0,\n",
    "        payment,\n",
    "        0\n",
    "    ).round(2)\n",
    "    return payment\n",
    "\n",
    "def calculate_debt_to_income_ratio(monthly_debt, monthly_loan_payment, monthly_income):\n",
    "    \"\"\"\n",
    "    Calculate Debt-To-Income Ratio.\n",
    "    \"\"\"\n",
    "    return (monthly_debt + monthly_loan_payment) / monthly_income\n",
    "\n",
    "def calculate_net_worth(total_assets, total_liabilities, min_net_worth=1000):\n",
    "    \"\"\"\n",
    "    Calculate Net Worth ensuring a minimum value.\n",
    "    \"\"\"\n",
    "    return np.maximum(total_assets - total_liabilities, min_net_worth)\n",
    "\n",
    "def calculate_approval_status(row):\n",
    "    \"\"\"\n",
    "    Determine loan approval status based on multiple factors.\n",
    "    \"\"\"\n",
    "    return calculate_approval_probability(\n",
    "        employment_status=row['Employment_Status'],\n",
    "        credit_score=row['Credit_Score'],\n",
    "        dti=row['Debt_To_IncomeRatio'],\n",
    "        loan_amount=row['Loan_Amount'],\n",
    "        vehicle_type=row['Vehicle_Type'],\n",
    "        annual_income=row['Annual_Income']\n",
    "    )\n",
    "\n",
    "def calculate_approval_probability(employment_status, credit_score, dti, loan_amount, vehicle_type, annual_income):\n",
    "    \"\"\"\n",
    "    Calculate the probability of loan approval based on various factors.\n",
    "    \"\"\"\n",
    "    probability = 0.0\n",
    "    \n",
    "    # Employment Status\n",
    "    if employment_status == 'Employed':\n",
    "        probability += 0.2\n",
    "    elif employment_status == 'Self-Employed':\n",
    "        probability += 0.15\n",
    "    elif employment_status == 'Unemployed':\n",
    "        probability -= 0.25\n",
    "    \n",
    "    # Credit Score\n",
    "    if credit_score >= 750:\n",
    "        probability += 0.35\n",
    "    elif 700 <= credit_score < 750:\n",
    "        probability += 0.25\n",
    "    elif 650 <= credit_score < 700:\n",
    "        probability += 0.15\n",
    "    else:\n",
    "        probability -= 0.35\n",
    "    \n",
    "    # Debt-To-Income Ratio\n",
    "    if dti <= 0.25:\n",
    "        probability += 0.35\n",
    "    elif 0.25 < dti <= 0.35:\n",
    "        probability += 0.25\n",
    "    elif 0.35 < dti <= 0.45:\n",
    "        probability += 0.15\n",
    "    else:\n",
    "        probability -= 0.35\n",
    "    \n",
    "    # Loan Amount\n",
    "    if loan_amount <= 20000:\n",
    "        probability += 0.15\n",
    "    elif 20000 < loan_amount <= 40000:\n",
    "        probability += 0.1\n",
    "    else:\n",
    "        probability -= 0.25\n",
    "    \n",
    "    # Annual Income\n",
    "    if annual_income >= 100000:\n",
    "        probability += 0.25\n",
    "    elif 75000 <= annual_income < 100000:\n",
    "        probability += 0.2\n",
    "    elif 50000 <= annual_income < 75000:\n",
    "        probability += 0.1\n",
    "    else:\n",
    "        probability -= 0.25\n",
    "    \n",
    "    # Vehicle Type\n",
    "    if vehicle_type == 'New':\n",
    "        probability += 0.1  # Slightly higher chance for new vehicles\n",
    "    \n",
    "    # Normalize probability between 0 and 1\n",
    "    probability = np.clip(probability, 0.0, 1.0)\n",
    "    \n",
    "    # Determine status based on thresholds\n",
    "    if probability >= 0.75:\n",
    "        return 'Approved'\n",
    "    elif probability >= 0.45:\n",
    "        return 'Pending'\n",
    "    else:\n",
    "        return 'Rejected'\n",
    "\n",
    "# ==========================\n",
    "# Data Generation\n",
    "# ==========================\n",
    "\n",
    "# Generate correlated personal and financial features\n",
    "age, experience, education_level, annual_income, credit_score, employment_status = generate_correlated_features(NUM_SAMPLES)\n",
    "\n",
    "# Generate application dates\n",
    "application_dates = generate_application_dates(NUM_SAMPLES)\n",
    "\n",
    "# Generate Vehicle Make based on weighted probabilities\n",
    "vehicle_make_probabilities = np.array(VEHICLE_MAKE_WEIGHTS) / sum(VEHICLE_MAKE_WEIGHTS)\n",
    "vehicle_makes = np.random.choice(VEHICLE_MAKES, size=NUM_SAMPLES, p=vehicle_make_probabilities)\n",
    "\n",
    "# Generate vehicle-related features\n",
    "vehicle_types, vehicle_models, vehicle_years, vehicle_mileage = generate_vehicle_features(NUM_SAMPLES, vehicle_makes)\n",
    "\n",
    "# Generate vehicle prices\n",
    "vehicle_prices = generate_vehicle_price(NUM_SAMPLES, vehicle_makes, vehicle_types, vehicle_years, vehicle_mileage)\n",
    "\n",
    "# Generate loan amounts\n",
    "loan_amounts = generate_loan_amount(vehicle_prices, vehicle_types)\n",
    "\n",
    "# Generate loan tenures based on loan amounts\n",
    "def generate_loan_tenures(loan_amounts):\n",
    "    \"\"\"\n",
    "    Generate loan tenure in years based on loan amount.\n",
    "    \"\"\"\n",
    "    tenure = np.zeros(NUM_SAMPLES, dtype=int)\n",
    "    tenure[loan_amounts > 30000] = np.random.choice([5, 6, 7], size=(loan_amounts > 30000).sum(), p=[0.5, 0.3, 0.2])\n",
    "    tenure[(loan_amounts > 20000) & (loan_amounts <= 30000)] = np.random.choice([4, 5, 6], size=((loan_amounts > 20000) & (loan_amounts <= 30000)).sum(), p=[0.4, 0.4, 0.2])\n",
    "    tenure[loan_amounts <= 20000] = np.random.choice([3, 4, 5], size=(loan_amounts <= 20000).sum(), p=[0.5, 0.3, 0.2])\n",
    "    return tenure\n",
    "\n",
    "loan_tenures = generate_loan_tenures(loan_amounts)\n",
    "\n",
    "# Generate interest rates\n",
    "interest_rates = generate_interest_rate(credit_score, loan_amounts, loan_tenures, annual_income)\n",
    "\n",
    "# Generate Loan Duration in months for amortization calculations\n",
    "loan_duration_months = loan_tenures * 12\n",
    "\n",
    "# Generate monthly loan payments\n",
    "monthly_loan_payments = calculate_monthly_loan_payment(loan_amounts, interest_rates, loan_tenures)\n",
    "\n",
    "# Generate monthly debt payments\n",
    "monthly_debt_payments = np.random.lognormal(6, 0.5, NUM_SAMPLES).astype(int)\n",
    "\n",
    "# Calculate Debt-To-Income Ratio\n",
    "dti_ratio = calculate_debt_to_income_ratio(monthly_debt_payments, monthly_loan_payments, annual_income / 12)\n",
    "\n",
    "# Generate location data\n",
    "locations = [fake.city() for _ in range(NUM_SAMPLES)]\n",
    "\n",
    "# ==========================\n",
    "# Additional Features\n",
    "# ==========================\n",
    "\n",
    "# Define additional categorical options\n",
    "marital_statuses = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "device_types = ['iPhone', 'Android', 'Windows Phone']\n",
    "os_versions = ['iOS 15', 'iOS 14', 'Android 11', 'Android 10', 'Windows 10 Mobile']\n",
    "app_versions = ['1.0', '1.1', '1.2']\n",
    "network_types = ['Wi-Fi', '4G', '5G']\n",
    "dealer_info = ['Dealer A', 'Dealer B', 'Dealer C', 'Dealer D']\n",
    "promotions = ['0% APR', '$1000 Cashback', 'No Payments for 90 Days', 'Low Down Payment']\n",
    "behavioral_segments = ['Low Engagement', 'Medium Engagement', 'High Engagement']\n",
    "user_types = ['New', 'Returning']\n",
    "common_issues = [None, 'Document Upload Failed', 'Credit Check Issue', 'App Crash']\n",
    "user_satisfactions = ['Very Satisfied', 'Satisfied', 'Neutral', 'Dissatisfied', 'Very Dissatisfied']\n",
    "\n",
    "# Generate the data dictionary\n",
    "data = {\n",
    "    'User_ID': [fake.uuid4() for _ in range(NUM_SAMPLES)],\n",
    "    'ApplicationDate': application_dates,\n",
    "    'Age': age,\n",
    "    'Gender': np.random.choice(['Male', 'Female'], size=NUM_SAMPLES),\n",
    "    'Annual_Income': annual_income,\n",
    "    'Credit_Score': credit_score,\n",
    "    'Employment_Status': employment_status,\n",
    "    'Education_Level': education_level,\n",
    "    'Experience': experience,\n",
    "    'Loan_Amount': loan_amounts,\n",
    "    'Loan_Tenure_Years': loan_tenures,\n",
    "    'Loan_Duration': np.random.choice(\n",
    "        [12, 24, 36, 48, 60, 72, 84, 96, 108, 120],\n",
    "        NUM_SAMPLES,\n",
    "        p=[0.05, 0.1, 0.2, 0.2, 0.2, 0.1, 0.05, 0.05, 0.025, 0.025]\n",
    "    ),\n",
    "    'Marital_Status': np.random.choice(marital_statuses, NUM_SAMPLES, p=[0.3, 0.5, 0.15, 0.05]),\n",
    "    'Number_Of_Dependents': np.random.choice([0, 1, 2, 3, 4, 5], NUM_SAMPLES, p=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03]),\n",
    "    'Home_Ownership_Status': np.random.choice(['Own', 'Rent', 'Mortgage', 'Other'], NUM_SAMPLES, p=[0.2, 0.3, 0.4, 0.1]),\n",
    "    'Monthly_Debt_Payments': monthly_debt_payments,\n",
    "    'Credit_Card_Utilization_Rate': np.random.beta(2, 5, NUM_SAMPLES),\n",
    "    'Number_Of_Open_CreditLines': np.random.poisson(3, NUM_SAMPLES).clip(0, 15).astype(int),\n",
    "    'Number_Of_Credit_Inquiries': np.random.poisson(1, NUM_SAMPLES).clip(0, 10).astype(int),\n",
    "    'Bankruptcy_History': np.random.choice([0, 1], NUM_SAMPLES, p=[0.95, 0.05]),\n",
    "    'Previous_Loan_Defaults': np.random.choice([0, 1], NUM_SAMPLES, p=[0.9, 0.1]),\n",
    "    'Payment_History': np.random.poisson(24, NUM_SAMPLES).clip(0, 60).astype(int),\n",
    "    'Length_Of_CreditHistory': np.random.randint(1, 30, NUM_SAMPLES),\n",
    "    'Savings_Account_Balance': np.random.lognormal(8, 1, NUM_SAMPLES).astype(int),\n",
    "    'Checking_Account_Balance': np.random.lognormal(7, 1, NUM_SAMPLES).astype(int),\n",
    "    'Total_Assets': np.random.lognormal(11, 1, NUM_SAMPLES).astype(int),\n",
    "    'Total_Liabilities': np.random.lognormal(10, 1, NUM_SAMPLES).astype(int),\n",
    "    'Monthly_Income': annual_income / 12,\n",
    "    'Utility_Bills_Payment_History': np.random.beta(8, 2, NUM_SAMPLES),\n",
    "    'Job_Tenure': np.random.poisson(5, NUM_SAMPLES).clip(0, 40).astype(int),\n",
    "    \n",
    "    # Vehicle-related features\n",
    "    'Location': locations,\n",
    "    'Vehicle_Type': vehicle_types,\n",
    "    'Vehicle_Make': vehicle_makes,\n",
    "    'Vehicle_Model': vehicle_models,\n",
    "    'Vehicle_Year': vehicle_years,\n",
    "    'Vehicle_Mileage': vehicle_mileage,\n",
    "    'Vehicle_Price': vehicle_prices,\n",
    "    'Down_Payment': np.random.randint(0.1 * vehicle_prices, 0.3 * vehicle_prices + 1).astype(int),\n",
    "    \n",
    "    # Interest Rate\n",
    "    'Interest_Rate': interest_rates,\n",
    "    \n",
    "    # Session and Interaction Features\n",
    "    'Session_Duration_Minutes': np.random.randint(5, 60, size=NUM_SAMPLES),\n",
    "    'Number_of_Interactions': np.random.randint(10, 100, size=NUM_SAMPLES),\n",
    "    'Notifications_Responded': np.random.choice([0, 1], size=NUM_SAMPLES, p=[0.7, 0.3]),\n",
    "    'Support_Queries': np.random.choice([0, 1, 2, 3], size=NUM_SAMPLES, p=[0.5, 0.3, 0.15, 0.05]),\n",
    "    'Application_Submitted': np.random.choice([True, False], size=NUM_SAMPLES, p=[0.8, 0.2])\n",
    "}\n",
    "\n",
    "# Additional Features\n",
    "additional_data = {\n",
    "    \"Monthly_Expenses\": np.random.randint(1000, 10000, size=NUM_SAMPLES),\n",
    "    \"Previous_Vehicle_Ownership\": np.random.choice([True, False], size=NUM_SAMPLES, p=[0.7, 0.3]),\n",
    "    \"Trade_In_Details\": np.random.choice([None, 'Old Car Trade-In'], size=NUM_SAMPLES, p=[0.7, 0.3]),\n",
    "    \"Session_Start_Time\": [fake.date_time_this_year() for _ in range(NUM_SAMPLES)],\n",
    "    \"Session_End_Time\": [fake.date_time_this_year() for _ in range(NUM_SAMPLES)],\n",
    "    \"Navigation_Paths\": [random.sample(EVENT_SEQUENCES, k=random.randint(3, len(EVENT_SEQUENCES))) for _ in range(NUM_SAMPLES)],\n",
    "    \"Device_Type\": np.random.choice(device_types, size=NUM_SAMPLES),\n",
    "    \"OS_Version\": np.random.choice(os_versions, size=NUM_SAMPLES),\n",
    "    \"App_Version\": np.random.choice(app_versions, size=NUM_SAMPLES),\n",
    "    \"Network_Type\": np.random.choice(network_types, size=NUM_SAMPLES),\n",
    "    \"Dealer_Info\": np.random.choice(dealer_info, size=NUM_SAMPLES),\n",
    "    \"Promotions\": np.random.choice(promotions, size=NUM_SAMPLES),\n",
    "    \"Regulatory_Compliance\": np.random.choice(['Compliant', 'Non-Compliant'], size=NUM_SAMPLES, p=[0.95, 0.05]),\n",
    "    \"Consent_Provided\": np.random.choice([True, False], size=NUM_SAMPLES, p=[0.98, 0.02]),\n",
    "    \"User_Type\": np.random.choice(user_types, size=NUM_SAMPLES),\n",
    "    \"Behavioral_Segment\": np.random.choice(behavioral_segments, size=NUM_SAMPLES),\n",
    "    \"User_Feedback_Rating\": np.random.randint(1, 5, size=NUM_SAMPLES),\n",
    "    \"Common_Issues_Faced\": np.random.choice(common_issues, size=NUM_SAMPLES, p=[0.7, 0.1, 0.1, 0.1]),\n",
    "    \"User_Satisfaction\": np.random.choice(user_satisfactions, size=NUM_SAMPLES)\n",
    "}\n",
    "\n",
    "# Update main data dictionary with additional features\n",
    "data.update(additional_data)\n",
    "\n",
    "# Interaction Event Data\n",
    "interaction_data = {\n",
    "    \"Frequency_of_App_Usage\": np.random.randint(1, 30, size=NUM_SAMPLES),\n",
    "    \"Clicks\": np.random.randint(1, 50, size=NUM_SAMPLES),\n",
    "    \"Taps\": np.random.randint(1, 50, size=NUM_SAMPLES),\n",
    "    \"Swipes\": np.random.randint(1, 50, size=NUM_SAMPLES),\n",
    "    \"Form_Entries\": np.random.randint(1, 20, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Home_Screen_Minutes\": np.random.randint(1, 10, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Loan_Calculator_Minutes\": np.random.randint(1, 15, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Vehicle_Selection_Minutes\": np.random.randint(1, 20, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Document_Upload_Minutes\": np.random.randint(1, 10, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Credit_Check_Minutes\": np.random.randint(1, 5, size=NUM_SAMPLES),\n",
    "    \"Time_Spent_on_Approval_Screen_Minutes\": np.random.randint(1, 5, size=NUM_SAMPLES),\n",
    "    \"Common_Paths\": [random.sample(SCREENS, k=random.randint(3, len(SCREENS))) for _ in range(NUM_SAMPLES)],\n",
    "    \"Drop_Off_Point\": np.random.choice(\n",
    "        SCREENS + [None],\n",
    "        size=NUM_SAMPLES,\n",
    "        p=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.4]  # 40% complete all steps\n",
    "    ),\n",
    "    \"Comparison_of_Loan_Options\": np.random.choice([True, False], size=NUM_SAMPLES, p=[0.6, 0.4])\n",
    "}\n",
    "\n",
    "# Update main data dictionary with interaction data\n",
    "data.update(interaction_data)\n",
    "\n",
    "# ==========================\n",
    "# Create DataFrame\n",
    "# ==========================\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ==========================\n",
    "# Feature Engineering\n",
    "# ==========================\n",
    "\n",
    "# Calculate Net Worth\n",
    "df['Total_Assets'] = np.maximum(df['Total_Assets'], df['Savings_Account_Balance'] + df['Checking_Account_Balance'])\n",
    "df['NetWorth'] = calculate_net_worth(df['Total_Assets'], df['Total_Liabilities'])\n",
    "\n",
    "# Calculate Monthly Loan Payment\n",
    "df['MonthlyLoanPayment'] = calculate_monthly_loan_payment(df['Loan_Amount'], df['Interest_Rate'], df['Loan_Tenure_Years'])\n",
    "\n",
    "# Recalculate Debt-To-Income Ratio\n",
    "df['Debt_To_IncomeRatio'] = calculate_debt_to_income_ratio(df['Monthly_Debt_Payments'], df['MonthlyLoanPayment'], df['Monthly_Income'])\n",
    "\n",
    "# Add Noise and Outliers\n",
    "# Add noise to Annual Income\n",
    "noise_mask = np.random.choice([True, False], NUM_SAMPLES, p=[0.01, 0.99])\n",
    "df.loc[noise_mask, 'Annual_Income'] = (\n",
    "    df.loc[noise_mask, 'Annual_Income'] * np.random.uniform(1.5, 2.0, noise_mask.sum())\n",
    ").astype(int)\n",
    "\n",
    "# Add random net worth to low net worth cases\n",
    "low_net_worth_mask = df['NetWorth'] == 1000\n",
    "df.loc[low_net_worth_mask, 'NetWorth'] += np.random.randint(0, 10000, size=low_net_worth_mask.sum())\n",
    "\n",
    "# ==========================\n",
    "# Loan Approval Processing\n",
    "# ==========================\n",
    "\n",
    "# Calculate Loan Approval Status\n",
    "df['LoanApproved'] = df.apply(calculate_approval_status, axis=1)\n",
    "\n",
    "# Ensure that approved loans have 'Approval' as the drop-off point\n",
    "df.loc[df['LoanApproved'] == 'Approved', 'Drop_Off_Point'] = 'Approval'\n",
    "\n",
    "# Assign Treatment Based on Drop-Off Point\n",
    "def assign_treatment(row):\n",
    "    if row['Drop_Off_Point'] == 'Approval':\n",
    "        return np.random.choice(TREATMENTS, p=[0.8, 0.2])\n",
    "    elif row['Drop_Off_Point'] in ['Document Upload', 'Credit Check']:\n",
    "        return np.random.choice(TREATMENTS, p=[0.5, 0.5])\n",
    "    else:\n",
    "        return 'No-Ads'\n",
    "\n",
    "df['Treatment_Assignment'] = df.apply(assign_treatment, axis=1)\n",
    "\n",
    "# ==========================\n",
    "# Final Adjustments\n",
    "# ==========================\n",
    "\n",
    "# Ensure Total Assets >= Savings + Checking\n",
    "df['Total_Assets'] = np.maximum(df['Total_Assets'], df['Savings_Account_Balance'] + df['Checking_Account_Balance'])\n",
    "\n",
    "# ==========================\n",
    "# Save to CSV\n",
    "# ==========================\n",
    "\n",
    "csv_file_path = \"Synthetic_Auto_Loan_Application_Data_jz3.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# ==========================\n",
    "# Optional: Display DataFrame Info\n",
    "# ==========================\n",
    "\n",
    "# Uncomment the following lines if you want to see a summary of the generated DataFrame\n",
    "# print(df.head())\n",
    "# print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb6344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
